{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI_project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\AI_project\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "csv_file_path_hum = \"./dataset/ì„œìš¸ì‹œ_ë³‘ì›.csv\"\n",
    "csv_file_path_ani = \"./dataset/ì„œìš¸ì‹œ_ë™ë¬¼ë³‘ì›.csv\"\n",
    "csv_file_path_post = \"./dataset/ì„œìš¸ì‹œ_ì‚°í›„ì¡°ë¦¬ì—….csv\"\n",
    "csv_file_path_pharm = \"./dataset/ì„œìš¸ì‹œ_ì•½êµ­.csv\"\n",
    "\n",
    "data_hum = pd.read_csv(csv_file_path_hum, encoding=\"cp949\")\n",
    "data_ani = pd.read_csv(csv_file_path_ani, encoding=\"cp949\")\n",
    "data_post = pd.read_csv(csv_file_path_post, encoding=\"cp949\")\n",
    "data_pharm = pd.read_csv(csv_file_path_pharm, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„ë¡œëª… ì£¼ì†Œ ì—†ì„ ì‹œ ì§€ë²ˆì£¼ì†Œë¡œ ëŒ€ì²´, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ'\n",
    "data_hum[\"ì£¼ì†Œ\"] = data_hum.apply(\n",
    "    lambda row: row[\"ë„ë¡œëª…ì£¼ì†Œ\"]\n",
    "    if pd.notnull(row[\"ë„ë¡œëª…ì£¼ì†Œ\"])\n",
    "    else (row[\"ì§€ë²ˆì£¼ì†Œ\"] if pd.notnull(row[\"ì§€ë²ˆì£¼ì†Œ\"]) else \"ì£¼ì†Œ ì •ë³´ ì—†ìŒ\"),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_ani[\"ì£¼ì†Œ\"] = data_ani.apply(\n",
    "    lambda row: row[\"ë„ë¡œëª…ì£¼ì†Œ\"]\n",
    "    if pd.notnull(row[\"ë„ë¡œëª…ì£¼ì†Œ\"])\n",
    "    else (row[\"ì§€ë²ˆì£¼ì†Œ\"] if pd.notnull(row[\"ì§€ë²ˆì£¼ì†Œ\"]) else \"ì£¼ì†Œ ì •ë³´ ì—†ìŒ\"),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_post[\"ì£¼ì†Œ\"] = data_post.apply(\n",
    "    lambda row: row[\"ë„ë¡œëª…ì£¼ì†Œ\"]\n",
    "    if pd.notnull(row[\"ë„ë¡œëª…ì£¼ì†Œ\"])\n",
    "    else (row[\"ì§€ë²ˆì£¼ì†Œ\"] if pd.notnull(row[\"ì§€ë²ˆì£¼ì†Œ\"]) else \"ì£¼ì†Œ ì •ë³´ ì—†ìŒ\"),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_pharm[\"ì£¼ì†Œ\"] = data_pharm.apply(\n",
    "    lambda row: row[\"ë„ë¡œëª…ì£¼ì†Œ\"]\n",
    "    if pd.notnull(row[\"ë„ë¡œëª…ì£¼ì†Œ\"])\n",
    "    else (row[\"ì§€ë²ˆì£¼ì†Œ\"] if pd.notnull(row[\"ì§€ë²ˆì£¼ì†Œ\"]) else \"ì£¼ì†Œ ì •ë³´ ì—†ìŒ\"),\n",
    "    axis=1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ì—…ìƒíƒœëª… ì²˜ë¦¬, íì—…ì‹œ íì—…ì¼ì, íœ´ì—…ì‹œ íœ´ì—…ì‹œì‘ì¼ì\n",
    "data_hum['ìƒíƒœ'] = data_hum.apply(\n",
    "    lambda row: \"ì˜ì—…ì¤‘\"\n",
    "    if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"ì˜ì—…/ì •ìƒ\"\n",
    "    else (\n",
    "        f\"íì—…ì¤‘ì…ë‹ˆë‹¤. íì—…ì¼ì : {row['íì—…ì¼ì']}\"\n",
    "        if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íì—…\"\n",
    "        else (\n",
    "            f\"íœ´ì—…ì¤‘ì…ë‹ˆë‹¤. íœ´ì—…ì‹œì‘ì¼ì : {row['íœ´ì—…ì‹œì‘ì¼ì']}\"\n",
    "            if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íœ´ì—…\"\n",
    "            else \"ìƒíƒœ ë¯¸í™•ì¸\"\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_ani['ìƒíƒœ'] = data_ani.apply(\n",
    "    lambda row: \"ì˜ì—…ì¤‘\"\n",
    "    if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"ì˜ì—…/ì •ìƒ\"\n",
    "    else (\n",
    "        f\"íì—…ì¤‘ì…ë‹ˆë‹¤. íì—…ì¼ì : {row['íì—…ì¼ì']}\"\n",
    "        if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íì—…\"\n",
    "        else (\n",
    "            f\"íœ´ì—…ì¤‘ì…ë‹ˆë‹¤. íœ´ì—…ì‹œì‘ì¼ì : {row['íœ´ì—…ì‹œì‘ì¼ì']}\"\n",
    "            if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íœ´ì—…\"\n",
    "            else \"ìƒíƒœ ë¯¸í™•ì¸\"\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_post['ìƒíƒœ'] = data_post.apply(\n",
    "    lambda row: \"ì˜ì—…ì¤‘\"\n",
    "    if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"ì˜ì—…/ì •ìƒ\"\n",
    "    else (\n",
    "        f\"íì—…ì¤‘ì…ë‹ˆë‹¤. íì—…ì¼ì : {row['íì—…ì¼ì']}\"\n",
    "        if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íì—…\"\n",
    "        else (\n",
    "            f\"íœ´ì—…ì¤‘ì…ë‹ˆë‹¤. íœ´ì—…ì‹œì‘ì¼ì : {row['íœ´ì—…ì‹œì‘ì¼ì']}\"\n",
    "            if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íœ´ì—…\"\n",
    "            else \"ìƒíƒœ ë¯¸í™•ì¸\"\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data_pharm['ìƒíƒœ'] = data_pharm.apply(\n",
    "    lambda row: \"ì˜ì—…ì¤‘\"\n",
    "    if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"ì˜ì—…/ì •ìƒ\"\n",
    "    else (\n",
    "        f\"íì—…ì¤‘ì…ë‹ˆë‹¤. íì—…ì¼ì : {row['íì—…ì¼ì']}\"\n",
    "        if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íì—…\"\n",
    "        else (\n",
    "            f\"íœ´ì—…ì¤‘ì…ë‹ˆë‹¤. íœ´ì—…ì‹œì‘ì¼ì : {row['íœ´ì—…ì‹œì‘ì¼ì']}\"\n",
    "            if row[\"ì˜ì—…ìƒíƒœëª…\"] == \"íœ´ì—…\"\n",
    "            else \"ìƒíƒœ ë¯¸í™•ì¸\"\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'info' ì—´ ìƒì„±\n",
    "col_to_use = [\"ìƒíƒœ\", \"ì „í™”ë²ˆí˜¸\", \"ì£¼ì†Œ\", \"ì‚¬ì—…ì¥ëª…\", \"ë°ì´í„°ê°±ì‹ ì¼ì\"]\n",
    "\n",
    "data_hum[\"info\"] = data_hum[[\"ìƒíƒœ\", \"ì „í™”ë²ˆí˜¸\", \"ì£¼ì†Œ\", \"ì‚¬ì—…ì¥ëª…\", \"ë°ì´í„°ê°±ì‹ ì¼ì\", \"ì—…íƒœêµ¬ë¶„ëª…\"]].apply(\n",
    "    lambda row: \" \".join(row.astype(str)), axis=1\n",
    ")\n",
    "data_ani[\"info\"] = data_ani[col_to_use].apply(lambda row: \" \".join(row.astype(str)), axis=1)\n",
    "data_post[\"info\"] = data_post[col_to_use].apply(lambda row: \" \".join(row.astype(str)), axis=1)\n",
    "data_pharm[\"info\"] = data_pharm[col_to_use].apply(lambda row: \" \".join(row.astype(str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document ê°ì²´ë¡œ ë³€í™˜\n",
    "documents_hum = [\n",
    "    Document(\n",
    "        page_content=row[\"info\"],\n",
    "        metadata={\n",
    "            \"ë³‘ì›ëª…\": row[\"ì‚¬ì—…ì¥ëª…\"],\n",
    "            \"ì£¼ì†Œ\": row[\"ì£¼ì†Œ\"],\n",
    "            \"ì „í™”ë²ˆí˜¸\": row[\"ì „í™”ë²ˆí˜¸\"],\n",
    "            \"ì§„ë£Œê³¼ëª©\": row.get(\"ì§„ë£Œê³¼ëª©ë‚´ìš©ëª…\", \"N/A\"),\n",
    "        },\n",
    "    )\n",
    "    for _, row in data_hum.iterrows()\n",
    "]\n",
    "\n",
    "documents_ani = [\n",
    "    Document(\n",
    "        page_content=row[\"info\"],\n",
    "        metadata={\n",
    "            \"ë³‘ì›ëª…\": row[\"ì‚¬ì—…ì¥ëª…\"],\n",
    "            \"ì£¼ì†Œ\": row[\"ì£¼ì†Œ\"],\n",
    "            \"ì „í™”ë²ˆí˜¸\": row[\"ì „í™”ë²ˆí˜¸\"],\n",
    "            \"ì§„ë£Œê³¼ëª©\": \"N/A\",  # ë™ë¬¼ë³‘ì› ë°ì´í„°ëŠ” ì§„ë£Œê³¼ëª© ì—†ìŒ\n",
    "        },\n",
    "    )\n",
    "    for _, row in data_ani.iterrows()\n",
    "]\n",
    "\n",
    "documents_post = [\n",
    "    Document(\n",
    "        page_content=row[\"info\"],\n",
    "        metadata={\n",
    "            \"ë³‘ì›ëª…\": row[\"ì‚¬ì—…ì¥ëª…\"],\n",
    "            \"ì£¼ì†Œ\": row[\"ì£¼ì†Œ\"],\n",
    "            \"ì „í™”ë²ˆí˜¸\": row[\"ì „í™”ë²ˆí˜¸\"],\n",
    "            \"ì§„ë£Œê³¼ëª©\": \"N/A\",  # ë™ë¬¼ë³‘ì› ë°ì´í„°ëŠ” ì§„ë£Œê³¼ëª© ì—†ìŒ\n",
    "        },\n",
    "    )\n",
    "    for _, row in data_post.iterrows()\n",
    "]\n",
    "\n",
    "documents_pharm = [\n",
    "    Document(\n",
    "        page_content=row[\"info\"],\n",
    "        metadata={\n",
    "            \"ë³‘ì›ëª…\": row[\"ì‚¬ì—…ì¥ëª…\"],\n",
    "            \"ì£¼ì†Œ\": row[\"ì£¼ì†Œ\"],\n",
    "            \"ì „í™”ë²ˆí˜¸\": row[\"ì „í™”ë²ˆí˜¸\"],\n",
    "            \"ì§„ë£Œê³¼ëª©\": \"N/A\",  # ë™ë¬¼ë³‘ì› ë°ì´í„°ëŠ” ì§„ë£Œê³¼ëª© ì—†ìŒ\n",
    "        },\n",
    "    )\n",
    "    for _, row in data_pharm.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ë²¡í„° ì„ë² ë”© ìƒì„±\n",
    "# token = \"<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>\"\n",
    "# embeddings = SentenceTransformer(\"jhgan/ko-sroberta-multitask\", use_auth_token=token)\n",
    "\n",
    "\n",
    "# # ê°ê°ì˜ documentsì— ëŒ€í•´ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# embeddings_hum = embeddings.encode([doc.page_content for doc in documents_hum])\n",
    "# embeddings_ani = embeddings.encode([doc.page_content for doc in documents_ani])\n",
    "# embeddings_post = embeddings.encode([doc.page_content for doc in documents_post])\n",
    "# embeddings_pharm = embeddings.encode([doc.page_content for doc in documents_pharm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human-15\\AppData\\Local\\Temp\\ipykernel_5912\\3812253994.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n"
     ]
    }
   ],
   "source": [
    "# HuggingFaceEmbeddings ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ê°ì²´ ìƒì„±\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_hum = FAISS.from_documents(documents_hum, embeddings)\n",
    "vectorstore_ani = FAISS.from_documents(documents_ani, embeddings)\n",
    "vectorstore_post = FAISS.from_documents(documents_post, embeddings)\n",
    "vectorstore_pharm = FAISS.from_documents(documents_pharm, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human-15\\AppData\\Local\\Temp\\ipykernel_5912\\412911231.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma2\", base_url=\"http://localhost:11434\")\n"
     ]
    }
   ],
   "source": [
    "# Ollama Gemma2 ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = Ollama(model=\"gemma2\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ê¸°(retriever) ì„¤ì •\n",
    "retriever_hum = vectorstore_hum.as_retriever()\n",
    "retriever_ani = vectorstore_ani.as_retriever()\n",
    "retriever_post = vectorstore_post.as_retriever()\n",
    "retriever_pharm = vectorstore_pharm.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì²´ì¸ ì„¤ì •\n",
    "qa_chain_hum = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_hum)\n",
    "qa_chain_ani = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_ani)\n",
    "qa_chain_post = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_post)\n",
    "qa_chain_pharm = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_pharm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAnswerGenerator:\n",
    "    \"\"\"í–¥ìƒëœ ë‹µë³€ ì¿¼ë¦¬ ìƒì„± í´ë˜ìŠ¤\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio í•¨ìˆ˜ ì •ì˜\n",
    "def human_hospital_bot(query):\n",
    "    response = qa_chain_hum.run(query)  # RAG ì²´ì¸ ì‚¬ìš©\n",
    "    return response\n",
    "\n",
    "\n",
    "def animal_hospital_bot(query):\n",
    "    response = qa_chain_ani.run(query) \n",
    "    return response\n",
    "\n",
    "def postpartum_hospital_bot(query):\n",
    "    response = qa_chain_post.run(query) \n",
    "    return response\n",
    "\n",
    "def pharmacy_hospital_bot(query):\n",
    "    response = qa_chain_pharm.run(query) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\n",
    "        \"## ğŸ¥ ë³‘ì› ì •ë³´ ì±—ë´‡\"\n",
    "    )  # ì±—ë´‡ì„ ì¢€ ë” ì§ê´€ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ì´ëª¨ì§€ ì‚¬ìš©\n",
    "\n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"ğŸ‘¨â€âš•ï¸ ë³‘ì›\"):\n",
    "            gr.Markdown(\"### ì‚¬ëŒ ë³‘ì› ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”!\")\n",
    "            human_query = gr.Textbox(label=\"ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ì˜ˆ: ìš”ì–‘ë³‘ì›ì€ ì–´ë””ìˆë‚˜ìš”?\")\n",
    "            human_response = gr.Textbox(label=\"ë‹µë³€\")\n",
    "            human_search_btn = gr.Button(\"ê²€ìƒ‰\")\n",
    "            human_search_btn.click(human_hospital_bot, inputs=[human_query], outputs=[human_response])\n",
    "\n",
    "        with gr.Tab(\"ğŸ¶ ë™ë¬¼ ë³‘ì›\"):\n",
    "            gr.Markdown(\"### ë™ë¬¼ ë³‘ì› ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”!\")\n",
    "            animal_query = gr.Textbox(label=\"ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ì˜ˆ: ê°•ë™êµ¬ì— ìˆëŠ” ë™ë¬¼ë³‘ì› ë¦¬ìŠ¤íŠ¸ë¥¼ ë½‘ì•„ì¤˜\")\n",
    "            animal_response = gr.Textbox(label=\"ë‹µë³€\")\n",
    "            animal_search_btn = gr.Button(\"ê²€ìƒ‰\")\n",
    "            animal_search_btn.click(animal_hospital_bot, inputs=[animal_query], outputs=[animal_response])\n",
    "\n",
    "        with gr.Tab(\"ğŸ‘¶ ì‚°í›„ì¡°ë¦¬ì›\"):\n",
    "            gr.Markdown(\"### ì‚°í›„ì¡°ë¦¬ì› ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”!\")\n",
    "            post_query = gr.Textbox(label=\"ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ì˜ˆ: êµ¬ë¡œêµ¬ì— ìˆëŠ” ì‚°í›„ì¡°ë¦¬ì› ì¤‘ ì˜ì—…ì¤‘ì¸ ì‚°í›„ì¡°ë¦¬ì›ì€ ì–´ë””ì— ìˆì–´?\")\n",
    "            post_response = gr.Textbox(label=\"ë‹µë³€\")\n",
    "            post_search_btn = gr.Button(\"ê²€ìƒ‰\")\n",
    "            post_search_btn.click(postpartum_hospital_bot, inputs=[post_query], outputs=[post_response])\n",
    "            \n",
    "        with gr.Tab(\"ğŸ’Š ì•½êµ­\"):\n",
    "            gr.Markdown(\"### ì•½êµ­ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”!\")\n",
    "            pharm_query = gr.Textbox(label=\"ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ì˜ˆ: í˜¸í˜¸ì•½êµ­ì˜ ì „í™”ë²ˆí˜¸ëŠ”?\")\n",
    "            pharm_response = gr.Textbox(label=\"ë‹µë³€\")\n",
    "            pharm_search_btn = gr.Button(\"ê²€ìƒ‰\")\n",
    "            pharm_search_btn.click(pharmacy_hospital_bot, inputs=[pharm_query], outputs=[pharm_response])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8957a32178f493bb00.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8957a32178f493bb00.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì•± ì‹¤í–‰\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
